## 데이터분석 준전문가(ADsP : Advanced Data Analytics Semi-Professional) 자격증 취득 과정
- ADsP : 데이터 이해에 대한 기본지식을 바탕으로 데이터분석 기획 및 데이터분석 등의 직무를 수행하는 실무자
- 내용 : ADSP 시험내용 중 데이터분석(통계분석, 정형 데이터 마이닝 등)의 문항 수와 기출빈도가 높은 이론과 실습 내용을 다루었음
- 동영상: 12개의 유튜브 동영상(10분 미만) 총 학습시간 100분

| # | 내용 | 참고 자료 |
|:----:|:-----------|--------|
| 00 | 머신러닝 소개 | [Introduction_to_Machine_learning)](https://github.com/ancestor9/ADSP-Crash-Course/blob/main/Introduction_to_Machine_learning_.ipynb)   |
| 01 | 회귀 모형(Regression Model)|  [Linear Regression](https://www.101ai.net/basics/linear-regression), [linear-regression](https://mlu-explain.github.io/linear-regression/)  [분산과편향](https://mlu-explain.github.io/bias-variance/), 회귀계수, [Loss & metrics](https://www.101ai.net/basics/loss-metric), [자료스케일링](https://www.101ai.net/basics/data-scaling) |
| 02 | 분류 모형(Classification Model) | [k-neighbors-classification](http://vision.stanford.edu/teaching/cs231n-demos/knn/)   |
| 03 | 로지스틱회귀 모형(Logistic Regression Model) |  [logistic-regression](https://mlu-explain.github.io/logistic-regression/), , 로지스틱회귀 계수, [Odds Ratio](https://github.com/ancestor9/ADSP-Crash-Course/blob/main/ADSP_%EA%B3%84%EC%82%B0%EB%AC%B8%EC%A0%9C.xlsx), Sigmoid 함수 |
| 04 | 의사결정나무 모형(Decision Tree Model) | [decision-tree](https://mlu-explain.github.io/decision-tree/),  Gini Index/Entropy/Information Gain, 과적합 방지를 위한 가지치기(Pruning)|
| 05 | 앙상블 모델(Ensemble Model)| [random-forest](https://mlu-explain.github.io/random-forest/),  Bagging, Random Forest, Boosting: AdaBoost, GBM, XGBoost, Voting/Stacking |
| 06 | 손실함수(Loss Function), 최적화(Optimization) | [교차검증](https://mlu-explain.github.io/cross-validation/), 하이퍼파라미터 튜닝 |
| 07 | 예측 모형 평가지표 1 | 혼동 행렬(Confusion Matrix), 정확도(Accuracy), [정밀도(Precision), 재현율(Recall)](https://mlu-explain.github.io/precision-recall/)의 개념 구분 (시험 빈출), F1-Score 및 기타 지표의 활용 |  |
| 08 | 예측 모형 평가지표 2 | [ROC](https://mlu-explain.github.io/roc-auc/), AUROC(AUC) 값(모형 성능 비교), 평가지표 계산 공식 대입 실습 (Confusion Matrix 기반), 적절한 평가 지표 선택 기준 (예: 암 진단 vs 스팸 필터)|  |
| 09 | 군집 분석 (Clustering) | [K-평균 군집(K-Means)](https://github.com/ancestor9/ADSP-Crash-Course/blob/main/Introduction_to_Machine_learning_.ipynb)의 원리와 초기 중심 설정, 계층적 군집(Hierarchical Clustering) (Dendrogram 해석), 군집 평가 지표 (실루엣 계수 등)|  |
| 10 | 연관 분석 (Association Analysis) | [연관 규칙 분석](https://github.com/ancestor9/ADSP-Crash-Course/blob/main/ADSP_%EA%B3%84%EC%82%B0%EB%AC%B8%EC%A0%9C.xlsx)- 지지도(Support), 신뢰도(Confidence), 향상도(Lift) - (시험 빈출 계산 문제)|  |
| 11 | 딥러닝 모형(Deep Learning Model) -1| 인공 신경망(ANN)의 구조 ([퍼셉트론](https://www.101ai.net/nnet/perceptron), [다층 신경망](https://www.101ai.net/nnet/multi-layer)), 활성화 함수 (ReLU, Sigmoid, Softmax)의 역할| |
| 12 | 딥러닝 모형(Deep Learning Model) -2| [손실 함수(Loss Function)](https://www.101ai.net/deeplearn/loss): MSE와 Cross-Entropy, [최적화(Optimization)](https://www.101ai.net/deeplearn/optimizer): 경사하강법(Gradient Descent), [역전파(Backpropagation)](https://www.101ai.net/nnet/backprop), [SOM(Self-Organizing Map)](https://github.com/ancestor9/ADSP-Crash-Course/blob/main/SOM.ipynb)| |


### 참고문헌
- [Visual explanations of core machine learning concepts](https://mlu-explain.github.io/)
- [Master AI Concepts with Interactive Learning!](https://www.101ai.net/overview/basics)
- [Image_Linear_Representation](https://www.youtube.com/watch?v=7Gtxd-ew4lk)
- [이미지 행렬 변환의 종류_CNN](https://github.com/ancestor9/ADSP-Crash-Course/blob/main/Image_representation.ipynb)
  ![](https://www.mlsysbook.ai/contents/core/dnn_architectures/dnn_architectures_files/mediabag/5aab87381f560ddc7f720233b9e89a654d299fa1.svg)
- [Google's Machine Learning Crash Course](https://developers.google.com/machine-learning?hl=ko)
- [K-means_elbow](https://ml-visualized.com/chapter2/k_means.html)
- [Introduction_to_Machine_learning](https://github.com/ancestor9/ADSP-Crash-Course/blob/main/Introduction_to_Machine_learning_.ipynb)

